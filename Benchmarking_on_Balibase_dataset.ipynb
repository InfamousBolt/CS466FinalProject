{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install biopython"
      ],
      "metadata": {
        "id": "UUY8JOzYXH1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from Bio import Align"
      ],
      "metadata": {
        "id": "nw5jIyLsVbnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://www.lbgi.fr/balibase/BalibaseDownload/BAliBASE_R1-5.tar.gz"
      ],
      "metadata": {
        "id": "pHxIJCY8dWdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xvzf BAliBASE_R1-5.tar.gz"
      ],
      "metadata": {
        "collapsed": true,
        "id": "jqktsvtCd9x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from Bio import SeqIO"
      ],
      "metadata": {
        "id": "G_B_FPhZgO0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def get_filenames_without_extension(directory):\n",
        "    \"\"\"\n",
        "    Collect filenames without extensions from a directory.\n",
        "    \"\"\"\n",
        "    filenames = []\n",
        "    for filename in os.listdir(directory):\n",
        "        if os.path.isfile(os.path.join(directory, filename)):\n",
        "            filenames.append(os.path.splitext(filename)[0])\n",
        "    return list(set(filenames))\n",
        "\n",
        "# Example usage\n",
        "# directory = \"/content/bb3_release/RV50\"\n",
        "# filenames_without_extension = get_filenames_without_extension(directory)\n",
        "# print(filenames_without_extension)\n",
        "# print(len(filenames_without_extension), len(list(set(filenames_without_extension))))\n"
      ],
      "metadata": {
        "id": "6kBmHYPVxgEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_balibase_directory(directory, extn):\n",
        "    \"\"\"\n",
        "    Parse the BAliBASE dataset to extract sequence pairs and reference alignments.\n",
        "    \"\"\"\n",
        "    alignment_files = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            print(file)\n",
        "            if file.endswith(extn):  # BAliBASE uses .tfa files for alignments\n",
        "                alignment_files.append(os.path.join(root, file))\n",
        "    return alignment_files"
      ],
      "metadata": {
        "id": "53XY71dsgss5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_sequences(file):\n",
        "    \"\"\"\n",
        "    Load sequences from a .tfa file.\n",
        "    \"\"\"\n",
        "    with open(file, \"r\") as f:\n",
        "        records = list(SeqIO.parse(f, \"fasta\"))\n",
        "    seq_dict = {}\n",
        "    for record in records:\n",
        "        seq_dict[record.name] = str(record.seq)\n",
        "        # record.seq = record.seq.upper()\n",
        "    return seq_dict"
      ],
      "metadata": {
        "id": "UKju704PgyPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sp_score(reference_alignment, test_alignment):\n",
        "    \"\"\"\n",
        "    Compute the Sum-of-Pairs (SP) score to evaluate alignment quality.\n",
        "    \"\"\"\n",
        "    ref_pairs = set()\n",
        "    test_pairs = set()\n",
        "\n",
        "    # Extract pair indices from reference alignment\n",
        "    for i in range(len(reference_alignment)):\n",
        "        for j in range(i + 1, len(reference_alignment)):\n",
        "            ref_seq_i = reference_alignment[i]\n",
        "            ref_seq_j = reference_alignment[j]\n",
        "            pair_indices = [\n",
        "                (k, l)\n",
        "                for k, l in zip(range(len(ref_seq_i)), range(len(ref_seq_j)))\n",
        "                if ref_seq_i[k] != '-' and ref_seq_j[l] != '-'\n",
        "            ]\n",
        "            ref_pairs.update(pair_indices)\n",
        "\n",
        "    # Extract pair indices from test alignment\n",
        "    for i in range(len(test_alignment)):\n",
        "        for j in range(i + 1, len(test_alignment)):\n",
        "            test_seq_i = test_alignment[i]\n",
        "            test_seq_j = test_alignment[j]\n",
        "            pair_indices = [\n",
        "                (k, l)\n",
        "                for k, l in zip(range(len(test_seq_i)), range(len(test_seq_j)))\n",
        "                if test_seq_i[k] != '-' and test_seq_j[l] != '-'\n",
        "            ]\n",
        "            test_pairs.update(pair_indices)\n",
        "\n",
        "    # Calculate SP score\n",
        "    sp_score = len(ref_pairs & test_pairs) / len(ref_pairs) if ref_pairs else 0\n",
        "    return sp_score\n",
        "\n",
        "\n",
        "def load_reference_alignment(file):\n",
        "    \"\"\"\n",
        "    Load reference alignments from a .msf file (formatted for BAliBASE).  Ref code: https://publish.illinois.edu/msaevaluation/files/2017/07/msf2fasta.txt\n",
        "    \"\"\"\n",
        "\n",
        "    with open(file) as f:\n",
        "        lines = f.read().splitlines()\n",
        "\n",
        "    # print(lines)\n",
        "    datadict={}\n",
        "    infosection=True\n",
        "    for i,line in enumerate(lines):\n",
        "        if not(infosection):\n",
        "            if any(c.isalpha() for c in line):\n",
        "                linesplit=line.split()\n",
        "                taxonname=linesplit[0]\n",
        "                subseq=''.join(linesplit[1:])\n",
        "                subseq=subseq.replace('.','-')\n",
        "                if taxonname in datadict:\n",
        "                    datadict[taxonname]=datadict[taxonname]+subseq\n",
        "                else:\n",
        "                    datadict[taxonname] = subseq\n",
        "        if line.startswith('//'):\n",
        "            infosection=False\n",
        "\n",
        "    return datadict"
      ],
      "metadata": {
        "id": "Ctjgc1mUg30r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "def evaluate_balibase(balibase_dir, gap_open=-11, gap_extend=-1, n_samples_per_file = 5):\n",
        "    \"\"\"\n",
        "    Evaluate Needleman-Wunsch algorithm with affine gap penalties on the BAliBASE dataset.\n",
        "    \"\"\"\n",
        "    filenames_without_extension = get_filenames_without_extension(balibase_dir)\n",
        "\n",
        "    # tfa_files = parse_balibase_directory(balibase_dir, \".tfa\")\n",
        "    # msf_files = parse_balibase_directory(balibase_dir, \".msf\")\n",
        "\n",
        "    truncated_sequences = []\n",
        "    full_lenth_sequences = []\n",
        "    for fname in filenames_without_extension:\n",
        "        if 'BBS' in fname:\n",
        "            truncated_sequences.append(fname)\n",
        "        else:\n",
        "            full_lenth_sequences.append(fname)\n",
        "\n",
        "\n",
        "    assert len(truncated_sequences) + len(full_lenth_sequences) == len(filenames_without_extension)\n",
        "\n",
        "    # print(len(truncated_sequences))\n",
        "    # print(len(full_lenth_sequences))\n",
        "    # return\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def compare_with_ref_sequences_and_muscle(fnames):\n",
        "        \"\"\"Compare the alignment with MUSCLE for validation of output\"\"\"\n",
        "        total_sp_score = 0\n",
        "        num_alignments = 0\n",
        "\n",
        "        for fname in tqdm(fnames):\n",
        "            tfa_file = os.path.join(balibase_dir, f\"{fname}.tfa\")\n",
        "            msf_file = os.path.join(balibase_dir, f\"{fname}.msf\")\n",
        "            unaligned_sequences_dict = load_sequences(tfa_file)\n",
        "\n",
        "            ref_algined_sequences_dict = load_reference_alignment(msf_file)\n",
        "            # ref_alignment = [str(record.seq) for record in records]\n",
        "\n",
        "            # print(len(ref_alignment))\n",
        "            # print(len(sequences))\n",
        "\n",
        "            # return\n",
        "\n",
        "\n",
        "            sequence_keys = list(set(unaligned_sequences_dict.keys()))\n",
        "            ref_keys = list(set(unaligned_sequences_dict.keys()))\n",
        "            assert sequence_keys == ref_keys\n",
        "\n",
        "            sequence_keys = sequence_keys[:n_samples_per_file]\n",
        "\n",
        "            # Pairwise evaluation (could extend to all combinations for larger datasets)\n",
        "\n",
        "            for i in range(len(sequence_keys)):\n",
        "                for j in range(i + 1, len(sequence_keys)):\n",
        "\n",
        "                    seq1 = unaligned_sequences_dict[sequence_keys[i]]\n",
        "                    seq2 = unaligned_sequences_dict[sequence_keys[j]]\n",
        "\n",
        "                    # Perform alignment using Needleman-Wunsch with affine gap penalties\n",
        "\n",
        "                    # try:\n",
        "                    aligned_seq1, aligned_seq2, score = get_alignment(seq1, seq2)\n",
        "\n",
        "                    # Compare with reference alignment\n",
        "                    # print(i, j)\n",
        "                    ref_alignment = [ref_algined_sequences_dict[sequence_keys[i]], ref_algined_sequences_dict[sequence_keys[j]]]\n",
        "                    sp = sp_score(ref_alignment, [aligned_seq1, aligned_seq2])\n",
        "\n",
        "                    # print([aligned_seq1, aligned_seq2])\n",
        "                    # print(f\"SP Score: {sp}\", score)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                    muscle_aligner = Align.PairwiseAligner()\n",
        "\n",
        "                    #we need to give MUSCLE similar scoring parameters as our function\n",
        "                    muscle_aligner.match_score = 1.0\n",
        "                    muscle_aligner.mismatch_score = -1.0\n",
        "                    muscle_aligner.open_gap_score = -11\n",
        "                    muscle_aligner.extend_gap_score = -1\n",
        "\n",
        "                    alignments = muscle_aligner.align(seq1, seq2)\n",
        "                    alignment = alignments[0]\n",
        "\n",
        "                    #we compare muscle score with our score.\n",
        "                    assert score == alignment.score\n",
        "\n",
        "                    total_sp_score += sp\n",
        "                    num_alignments += 1\n",
        "                    # except:\n",
        "                    #     continue\n",
        "\n",
        "            avg_sp_score = total_sp_score / num_alignments if num_alignments > 0 else 0\n",
        "        return avg_sp_score\n",
        "\n",
        "\n",
        "    sp_scores_full_length = compare_with_ref_sequences_and_muscle(full_lenth_sequences)\n",
        "    sp_scores_truncated = compare_with_ref_sequences_and_muscle(truncated_sequences)\n",
        "\n",
        "    print(f\"Average SP Score on BAliBASE with full-length sequences: {sp_scores_full_length}\")\n",
        "    print(f\"Average SP Score on BAliBASE with truncated sequences: {sp_scores_truncated}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IOcXVUn7g8ZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import your algorithm here\n",
        "\n",
        "# from nwag2 import NeedlemanWunschAffineGap\n",
        "\n",
        "# # needleman_wunsch_fn = NeedlemanWunschAffineGap()\n",
        "\n",
        "needleman_wunsch_fn = NeedlemanWunschAffine(match_score=1, mismatch_score=-1, gap_open=-11, gap_extend=-1)\n",
        "\n",
        "def get_alignment(seq1, seq2):\n",
        "    aligned_seq1, aligned_seq2, score = needleman_wunsch_fn.align(seq1, seq2)\n",
        "    return aligned_seq1, aligned_seq2, score\n",
        "\n",
        "evaluate_balibase(\"/content/bb3_release/RV50\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "z0jmHDZChg24"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}